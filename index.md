---
layout: resume
excerpt: Home
---

## About Me

I am currently a _Research Scientist_ at Siri Speech, Apple. My research at Apple focuses on _distributed (federated) learning_ and/or _active learning_ towards large-scale _production-oriented_ ASR models, with an aim to address challenges related to _privacy_, data/device heterogeneity, large-model training, data scarcity, _personalization_, and interpretability.

I joined Apple's Class of 2022 _AIML Residents_ in July, 2022 after graduating with a Master of Science (MS) with thesis titled ["Towards Privacy and Communication Efficiency in Distributed Representation Learning."](/publications#t1)) from the [School of Electrical and Computer Engineering](https://engineering.purdue.edu/ECE){:target="_blank"}, [Purdue Univesity](https://www.purdue.edu/){:target="_blank"} advised by [Dr. Christopher Brinton](http://www.cbrinton.net/){:target="_blank"}. During graduate studies, I also actively collaborated with [Dr. David Inouye](https://www.davidinouye.com){:target="_blank"}, [Dr. Qiang Qiu](https://web.ics.purdue.edu/~qqiu/){:target="_blank"}, [Dr. Saurabh Bagchi](https://engineering.purdue.edu/~sbagchi/){:target="_blank"}, and [Dr. Seyyedali Hosseinalipour](https://sites.google.com/ncsu.edu/seyyedalihosseinalipour){:target="_blank"}.

<!--
I received my Bachelor's degree in [Electrical and Electronics Engineering](https://eee.nitk.ac.in/){:target="_blank"} from the [National Institute of Technology Karnataka](https://www.nitk.ac.in/){:target="_blank"} in 2015. My Bachelor's thesis focused on "Supervised and Unsupervised Techniques for Image Segmentation" advised by [Dr. Ashvini Chaturvedi](https://ece.nitk.ac.in/professor/ashvini-chaturvedi){:target="_blank"}. I also collaborated with [Dr. K Manjunatha Sharma](https://eee.nitk.ac.in/professor/KMS){:target="_blank"} on miniprojects to develop smart-switches using signal processing and ML techniques.

Prior to joining Purdue, I worked for a year as a Research Scientist at a California-based AI-solutions startup [Foundation AI](https://www.foundationai.com/){:target="_blank"} and for over 3 years as Data Scientist at a Bangalore-based healthcare startup [Practo](https://www.practo.com/){:target="_blank"}. During my time in the industry, I have built scalable ML solutions deployed in production tackling real-world problems by leveraging advances in computer vision (CV), Natural Language Processing (NLP) and Deep Learning (DL).
-->

## Research Interests
My research interest lies at the intersection of _Representation Learning, Density Estimation, and Distributed Learning_. One of the main focuses of my work is to reduce the dependence on a  _large labeled dataset_ in model training by developing algorithms that are either predominantly  _unsupervised, self-supervised_ and/or _federated_ in nature. I also have an interest in the design and analysis of representation learning algorithms that are _scalable, communication-efficient, memory-efficient, and robust_ to adversarial perturbations. I have recently started exploring the role of deep reinforcement learning and its integration with unsupervised learning.

## Recent Updates

- November, 2023
    - Our paper ["Federated Learning for Speech Recognition: Revisiting Current Trends Towards Large-Scale ASR."](https://openreview.net/forum?id=ozN92d7CHX){:target="_blank"} got accepted at the [International Workshop on Federated Learning in the Age of Foundation Models in Conjunction with NeurIPS, 2023](https://federated-learning.org/fl@fm-neurips-2023/){:target="_blank"}

- September, 2023
    - Preprint of our paper ["Federated Learning with Differential Privacy for End-to-End Speech Recognition"](https://arxiv.org/abs/2310.00098){:target="_blank"} is available.
    - Our paper ["Importance of Smoothness Induced by Optimizers in FL4ASR: Towards Understanding Federated Learning for End-to-End ASR."](https://arxiv.org/abs/2309.13102){:target="_blank"} got accepted at the [IEEE Automatic Speech Recognition and Understanding Workshop (ASRU), 2023](http://www.asru2023.org/){:target="_blank"}

- July, 2023
    - Joined Apple as a Research Scientist after finishing the [AIML Residency Program, 2022](https://machinelearning.apple.com/updates/aiml-residency-program-application){:target="_blank"}.

- Jan, 2023
    - Our paper ["Efficient Federated Domain Translation"](https://openreview.net/forum?id=uhLAcrAZ9cJ){:target="_blank"} got accepted at the [International Conference on Learning Representations (ICLR), 2023](https://iclr.cc/){:target="_blank"}.

<!--
- May, 2022
    - Selected as 1 among the 10 [AIML Residents at Apple](https://machinelearning.apple.com/updates/aiml-residency-program-application){:target="_blank"} for the year 2022.
    - Successfully defended M.S. thesis: ["Towards Privacy and Communication Efficiency in Distributed Representation Learning"](https://hammer.purdue.edu/articles/thesis/Towards_Privacy_and_Communication_Efficiency_in_Distributed_Representation_Learning/20029550/1){:target="_blank"}

    - We submitted our paper "Efficient Federated Domain Translation" to [NeurIPS, 2022](https://nips.cc/Conferences/2022/Dates){:target="_blank"}
- March, 2022
    - Selected for [Google Research](https://research.google/){:target="_blank"} Summer Internship, 2022.
    - Got an offer for returning as Applied Science Intern at [Zillow Group](https://www.zillowgroup.com/){:target="_blank"} for Summer, 2022.

- January, 2022
    - Our paper ["Recycling Model Updates in Federated Learning: Are Gradient Subspaces Low-Rank?"](https://openreview.net/forum?id=B7ZbqNLDn-_){:target="_blank"} got accepted at the [International Conference on Learning Representations (ICLR), 2022](https://iclr.cc/){:target="_blank"}.
    - Our paper ["Can we Generalize and Distribute Private Representation Learning?"](https://proceedings.mlr.press/v151/shams-azam22a.html){:target="_blank"} got accepted at the [International Conference on Artificial Intelligence and Statistics (AISTATS), 2022](http://aistats.org/aistats2022/){:target="_blank"}.
    - Our paper ["Multi-Stage Hybrid Federated Learning over Large-Scale Wireless Fog Networks"](https://ieeexplore.ieee.org/document/9705093){:target="_blank"} got accepted at [IEEE/ACM Transactions on Networking Journal](https://newslab.ece.ohio-state.edu/ton/){:target="_blank"}.
    - Conference submission to [ICLR 2022](https://iclr.cc/){:target="_blank"}: Rank Deficiency of SGD: A Gradient-Space Exploration and it's Exploitation in Federated Learning.
- 2021
    - Our paper ["A Generalized and Distributable Generative Model for Private Representation Learning"](https://openreview.net/forum?id=cRKEnMKHY_z){:target="_blank"} got accepted at the [NeurIPS Workshop on Deep Generative Models and Downstream Applications 2021](https://dgms-and-applications.github.io/2021/){:target="_blank"}.
    - Our paper ["Semi-decentralized Federated Learning with Cooperative D2D Local Model Aggregations"](https://ieeexplore.ieee.org/abstract/document/9562522){:target="_blank"} got accepted at [IEEE Journal on Selected Areas in Communication (JSAC)](https://www.comsoc.org/publications/journals/ieee-jsac){:target="_blank"}. An abridged version ["Federated Learning Beyond the Star: Local D2D Model Consensus with Global Cluster Sampling"](https://arxiv.org/abs/2109.03350){:target="_blank"} also got accepted at [IEEE Globecom](https://globecom2021.ieee-globecom.org/){:target="_blank"}, 2021.
    - Our paper ["Multi-Stage Hybrid Federated Learning over Large-Scale Wireless Fog Networks"](https://arxiv.org/abs/2007.09511){:target="_blank"} received a _minor revision_ decision from the [IEEE/ACM Transactions on Networking Journal](https://newslab.ece.ohio-state.edu/ton/){:target="_blank"}.
-->
